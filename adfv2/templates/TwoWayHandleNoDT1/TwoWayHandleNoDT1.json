{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name"
		},
		"AzureDataLakeStorageADF1": {
			"type": "string"
		},
		"linkedServiceAQLADF": {
			"type": "string"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/TwoWayHandleNoDT')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "TwoWayHandleNoDT",
						"description": "This Data Flow runs CRUD operations on a parquet sink using the following Parquet Inputs:\n1. Primary Key Table: a list of primary keys of rows that exist. This can be both the master list of primary keys or just a list of primary keys of rows that have been inserted/updated\n2. Input Data: A List of rows that are inserted, updated and deleted\n3. Existing Data: The existing sink data base\n\nThe output of this Data Flow is the equivalent of a MERGE command in SQL",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "TwoWaysToHandleData",
								"type": "DataFlowReference"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							}
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/TwoWaysToHandleData')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/TwoWaysToHandleData')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "This Data Flow shows two ways to handle data without datetime information",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "InputParquet",
								"type": "DatasetReference"
							},
							"name": "OldInputData"
						},
						{
							"dataset": {
								"referenceName": "InputParquet",
								"type": "DatasetReference"
							},
							"name": "InputData"
						},
						{
							"dataset": {
								"referenceName": "InputParquet",
								"type": "DatasetReference"
							},
							"name": "InputData2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlDatabaseSinkDataset",
								"type": "DatasetReference"
							},
							"name": "ToDWHTruckAndInserts"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlDatabaseSinkDataset",
								"type": "DatasetReference"
							},
							"name": "Sink2AzureSQLDB"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlDatabaseSinkDataset",
								"type": "DatasetReference"
							},
							"name": "Sink1AzureSQLDB"
						}
					],
					"transformations": [
						{
							"name": "FilterNewRecords"
						},
						{
							"name": "FilterUpdatedRecords"
						},
						{
							"name": "AlterRow1"
						}
					],
					"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tpartitionBy('roundRobin', 2)) ~> OldInputData\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tpartitionBy('roundRobin', 2)) ~> InputData\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet') ~> InputData2\nInputData, OldInputData exists(InputData@RecID == OldInputData@RecID,\n\tnegate:true,\n\tbroadcast: 'auto')~> FilterNewRecords\nOldInputData, InputData exists(OldInputData@RecID == InputData@RecID && InputData@RecVersion != OldInputData@RecVersion,\n\tnegate:false,\n\tbroadcast: 'auto')~> FilterUpdatedRecords\nFilterUpdatedRecords alterRow(updateIf(true())) ~> AlterRow1\nInputData2 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\ttruncate:true,\n\tformat: 'table',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> ToDWHTruckAndInserts\nFilterNewRecords sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tformat: 'table',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> Sink2AzureSQLDB\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:false,\n\tupdateable:false,\n\tupsertable:true,\n\tformat: 'table',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> Sink1AzureSQLDB"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/InputParquet')]",
				"[concat(variables('factoryId'), '/datasets/AzureSqlDatabaseSinkDataset')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/InputParquet')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "[parameters('AzureDataLakeStorageADF1')]",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "sales",
						"fileSystem": "datalake"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/AzureSqlDatabaseSinkDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Connection to your destination data store.",
				"linkedServiceName": {
					"referenceName": "[parameters('linkedServiceAQLADF')]",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"sinkTableName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": {
						"value": "@dataset().sinkTableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": []
		}
	]
}